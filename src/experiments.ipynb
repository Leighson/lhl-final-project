{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection: Bounding Box Regressiong with Keras, TensorFlow, and Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom deep learning model to perform object detection via bounding box regression with Keras and Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic R-CNN Object Detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These detectors rely on the concept of **region proposal** regenerators.\n",
    "\n",
    "These region proposal algorithms (e.g., Selective Search) examing an input image and then identify where a potential object _could_ be. It doesn't yet know if an object exists in a given location, just that the area of the image looks interesting and warrants further inspection.\n",
    "\n",
    "In the classic implementation,these region proposals were used to extract output features from a pre-trained CNN and then were fed into an SVM for final classification. In this implementation, the location from the regional proposal was treated as the bounding box, while the SVM produced the class label for the bounding box region.\n",
    "\n",
    "Essentially, the original R-CNN architecture didn't _learn_ how to detect bounding boxes--it was not end-to-end trainable. The key then is the concept of bounding box regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Bounding Box Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Image Classification`:\n",
    "- present an input image to the CNN\n",
    "- perform a forward pass through the CNN\n",
    "- output a vector with _N_ elements, where _N_ is the total number of class labels\n",
    "- select the class label with the largest probability as our final predicted class label\n",
    "\n",
    "Unfortunately, that type of model doesn't translate to object detection. It would be impossible for us to construct a class label for every possible combination of xy-coordinate bounding boxes in an input image.\n",
    "\n",
    "Instead, we need to rely on a different type of machine learning called _regression_. Unlike classification, which produces a label, regression enables us to predict continuous values.\n",
    "\n",
    "Typically, we scale the output range of values to [0, 1] during training and then scale the outputs back after prediction (if needed).\n",
    "\n",
    "`Bounding Box Regression`:\n",
    "- at the head of the network, place a fully-connected layer with four neurons corresponding to the top-left and bottom-right xy-coordinates\n",
    "- given that four-neuron layer, implement a sigmoid activation function such that the outputs are returned in the range of [0, 1]\n",
    "- train the model using a loss function such as MSE or MAE on training data that consists of:\n",
    "    1. the input images\n",
    "    2. the bounding box of the object in the image\n",
    "\n",
    "After Training, we can present an input image to our bounding box regressor network. Our network will then perform a forward pass and then predict the output bounding box coordinates of the object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dynamic Paths to Configuration File, `config.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_PATH = '../data/caltech-101/'\n",
    "IMAGES_PATH = os.path.sep.join([BASE_PATH, '101_ObjectCategories/airplanes'])\n",
    "ANNOTS_PATH = os.path.sep.join([BASE_PATH, 'Annotations/Airplanes_Side_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "annots = loadmat(os.path.sep.join([ANNOTS_PATH, 'annotation_0001.mat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN, Created on: Tue Dec 14 11:03:29 2004',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'box_coord': array([[ 30, 137,  49, 349]], dtype=uint16),\n",
       " 'obj_contour': array([[  8.54082661,  11.87852823,   1.86542339,   1.56199597,\n",
       "          31.60131048,  27.65675403,  23.71219758,  18.85735887,\n",
       "          18.85735887,  31.60131048,  47.68296371,  51.32409274,\n",
       "          59.51663306,  60.1234879 ,  56.78578629,  78.02570565,\n",
       "          91.07308468, 178.46018145, 179.97731855, 222.15372984,\n",
       "         225.79485887, 239.75252016, 265.84727823, 298.92086694,\n",
       "         300.13457661, 298.3140121 , 265.54385081, 264.63356855,\n",
       "         270.39868952, 268.88155242, 265.84727823, 264.02671371,\n",
       "         260.08215726, 255.83417339, 257.6547379 , 261.90272177,\n",
       "         261.90272177, 160.25453629, 160.25453629, 156.00655242,\n",
       "         155.39969758, 149.33114919, 142.04889113, 139.31804435,\n",
       "         139.92489919, 143.26260081, 136.28377016, 128.09122984,\n",
       "         124.45010081, 123.53981855, 122.93296371, 117.47127016,\n",
       "          73.77772177,  68.61945565,  44.95211694,  38.27671371,\n",
       "          36.15272177,   8.23739919,   8.54082661],\n",
       "        [ 75.89163306,  62.54082661,  59.80997984,  56.77570565,\n",
       "          51.01058468,  35.23235887,  11.26159274,  10.35131048,\n",
       "           6.10332661,   1.2484879 ,   3.37247984,  12.171875  ,\n",
       "          12.47530242,  19.15070565,  18.54385081,  47.97631048,\n",
       "          51.3140121 ,  49.19002016,  44.03175403,  45.54889113,\n",
       "          51.3140121 ,  55.25856855,  72.85735887,  85.60131048,\n",
       "          90.15272177,  90.75957661,  92.58014113,  94.09727823,\n",
       "          95.3109879 , 100.77268145, 101.37953629, 104.7172379 ,\n",
       "         105.93094758, 102.28981855,  95.3109879 ,  94.70413306,\n",
       "          91.66985887,  90.15272177,  97.13155242,  97.73840726,\n",
       "         102.89667339, 105.32409274, 104.7172379 ,  97.43497984,\n",
       "          93.79385081,  91.36643145,  88.9390121 ,  88.33215726,\n",
       "          92.88356855,  92.58014113,  88.63558468,  86.81502016,\n",
       "          83.78074597,  85.9047379 ,  82.87046371,  85.60131048,\n",
       "          80.13961694,  75.28477823,  75.58820565]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import config, utils\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme(style='darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 640, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread(f'{config.BASE_PATH}/thumb_01_01_0001.jpg').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "    \n",
    "if config.COLORSPACE == 'grayscale':\n",
    "    for location in utils.get_image_locs():\n",
    "        images.append(cv2.imread(location, cv2.IMREAD_GRAYSCALE))\n",
    "        \n",
    "elif config.COLORSPACE == 'alpha':\n",
    "    for location in utils.get_image_locs():\n",
    "        images.append(cv2.imread(location, cv2.IMREAD_UNCHANGED))\n",
    "        \n",
    "else:\n",
    "    for location in utils.get_image_locs():\n",
    "        images.append(cv2.imread(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numpy = np.array(images)\n",
    "names = ['image', 'height', 'width']\n",
    "index = pd.MultiIndex.from_product(\n",
    "    [range(dim) for dim in image_numpy.shape],\n",
    "    names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(5999, 480, 640, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Volumes/GoogleDrive/My Drive/Colab Notebooks/lighthouse-final-project/src/experiments.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/GoogleDrive/My%20Drive/Colab%20Notebooks/lighthouse-final-project/src/experiments.ipynb#ch0000012?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39;49mDataFrame(images)\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/pandas/core/frame.py:737\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    729\u001b[0m         mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    730\u001b[0m             arrays,\n\u001b[1;32m    731\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    735\u001b[0m         )\n\u001b[1;32m    736\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 737\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    738\u001b[0m             data,\n\u001b[1;32m    739\u001b[0m             index,\n\u001b[1;32m    740\u001b[0m             columns,\n\u001b[1;32m    741\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    742\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    743\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[1;32m    744\u001b[0m         )\n\u001b[1;32m    745\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    747\u001b[0m         {},\n\u001b[1;32m    748\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    751\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    752\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/pandas/core/internals/construction.py:331\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    326\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarray(values, copy\u001b[39m=\u001b[39;49mcopy_on_sanitize)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[1;32m    334\u001b[0m     shape \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/lighthouse/lib/python3.8/site-packages/pandas/core/internals/construction.py:591\u001b[0m, in \u001b[0;36m_prep_ndarray\u001b[0;34m(values, copy)\u001b[0m\n\u001b[1;32m    589\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[1;32m    590\u001b[0m \u001b[39melif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 591\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMust pass 2-d input. shape=\u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    593\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=(5999, 480, 640, 3)"
     ]
    }
   ],
   "source": [
    "names = ['image', 'height', 'width']\n",
    "img_numpy = np.array(images)\n",
    "\n",
    "# iterate through shapes and assign names\n",
    "index = pd.MultiIndex.from_product(\n",
    "    [range(dim) for dim in img_numpy.shape],\n",
    "    names=names)\n",
    "\n",
    "# use multiindexing to configure the dataframe\n",
    "img_df = pd.DataFrame(\n",
    "    { names[0] : img_numpy.flatten() },\n",
    "    index=index)\n",
    "\n",
    "img_df = img_df['image']\n",
    "img_df = img_df.unstack(level='width').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lighthouse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6bdb6bebcaa6c165db367a86e382ae8df75f09257c40532b854029e0e3d706f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
